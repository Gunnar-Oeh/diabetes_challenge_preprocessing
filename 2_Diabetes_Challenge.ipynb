{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DMxwdKZdaan"
   },
   "source": [
    "# Diabetes Challenge\n",
    "\n",
    "Your task today is to **analyze** the Kaggle \"Pima Indians Diabetes Database\" and to **predict** whether a patient has Diabetes or not.\n",
    "\n",
    "## Task:\n",
    "- Load the data from the database. The schema is called `diabetes`. To connect to the database you need to copy the `.env` file from the visualization or hands-on-ml repository into this repo. Explore the database, try to establish what the relationships between the tables are (1-1, 1-N, N-M). Explain to yourself and the group what data do you see and whether it makes sense. What JOINs are appropriate to use and why? \n",
    "- Use at least two different classification algorithms we have learned so far to predict Diabetes patients. \n",
    "- Discuss before you start with the modeling process which **evaluation metric** you choose and explain why.\n",
    "- Implement a GridSearchCV or RandomizedSearchCV to tune the hyperparameters of your model.\n",
    "- **Optional:** If you have time at the end, try to use sklearn's pipline module to encapsulate all the steps into a pipeline.\n",
    "\n",
    "Don't forget to split your data in train and test set. And analyze your final model on the test data. It might also be necessary to scale your data in order to improve the performance of some of the models.\n",
    "\n",
    "\n",
    "## Helpful links and advise:\n",
    "- [sklearn documentation on hyperparameter tuning](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)\n",
    "- It might be helpful to check some sources on how to deal with imbalanced data. \n",
    "    * [8 Tactics to Combat Imbalanced Classes](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)\n",
    "    * [Random-Oversampling/Undersampling](https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFFBgjcYhrt8"
   },
   "source": [
    "# Data Description\n",
    "\n",
    "## Context\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "## Acknowledgements\n",
    "Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261--265). IEEE Computer Society Press.\n",
    "\n",
    "## About this dataset\n",
    "The datasets consist of several medical predictor (independent) variables and one target (dependent) variable, Outcome. Independent variables include the number of pregnancies the patient has had, their BMI, insulin level, age, and so on. For the outcome class value 1 is interpreted as \"tested positive for diabetes\".\n",
    "\n",
    "|Column Name| Description|\n",
    "|:------------|:------------|\n",
    "|Pregnancies|Number of times pregnant|\n",
    "|Glucose|Plasma glucose concentration a 2 hours in an oral glucose tolerance test|\n",
    "|BloodPressure|Diastolic blood pressure (mm Hg)|\n",
    "|SkinThickness|Triceps skin fold thickness (mm)|\n",
    "|Insulin|2-Hour serum insulin (mu U/ml)|\n",
    "|BMI|Body mass index (weight in kg/(height in m)^2)|\n",
    "|DiabetesPedigreeFunction| Diabetes pedigree function|\n",
    "|Age| Age (years)|\n",
    "|Outcome|Class variable (0 or 1) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of relevant packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Set random seed \n",
    "RSEED = 42\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import .env\n",
    "# Inspect and make sql query in DBEAVER\n",
    "# Load Data\n",
    "# Train test split data\n",
    "# Inspect data\n",
    "# Pairplot\n",
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read database string from .env file (no need to change anything)\n",
    "load_dotenv()\n",
    "\n",
    "DB_STRING = os.getenv('DB_STRING')\n",
    "\n",
    "db = create_engine(DB_STRING)\n",
    "\n",
    "# SQL-Statement\n",
    "sql_str = \"\"\"SET SCHEMA 'diabetes';\n",
    "SELECT p.id AS patient_id, p.\"Age\", p.pregnancies, p.bmi,\n",
    "pdg.diabetespedigreefunction AS pdg_function, pdg.outcome AS outcome,\n",
    "sk.skinthickness AS skinthickness,\n",
    "bm.insulin AS insulin,\n",
    "bm.glucose AS glucose,\n",
    "bm.bloodpressure AS bpres\n",
    "FROM patient AS p\n",
    "INNER JOIN pedigree_outcome AS pdg\n",
    "ON p.id = pdg.patientid\n",
    "INNER JOIN skin AS sk\n",
    "ON p.id = sk.patientid\n",
    "INNER JOIN blood_metrics AS bm \n",
    "ON p.id = bm.patientid\n",
    "AND bm.measurement_date = '2022-12-13'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Table from Query\n",
    "# Import with pandas\n",
    "df_diab = pd.read_sql(sql_str, db)\n",
    "df_diab.head()\n",
    "\n",
    "df_diab.to_csv(\"diabetes_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inspect data\n",
    "df_diab.head()\n",
    "df_diab.info() ### All non null, but entries with 0 in it\n",
    "df_diab.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove 0 entries from dataset? - function in preprocessing\n",
    "\n",
    "def detect_zero(col): # Return Index\n",
    "    ind = col == 0\n",
    "    return sum (ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diab.apply(lambda x: detect_zero(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Doesnt Make sense for bmi 11, skinthickness 227, glucose 5, bpres 35\n",
    "- replace 0 with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pairplot without patient_id\n",
    "sns.pairplot(df_diab.drop(\"patient_id\", axis = 1), hue = \"outcome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train test split\n",
    "X = df_diab.drop([\"patient_id\", \"outcome\"], axis = 1)\n",
    "y = df_diab.outcome\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove zeros: \"mi\", \"skinthickness\", \"glucose\", \"bpres\"\n",
    "col_zero = [\"bmi\", \"skinthickness\", \"glucose\", \"bpres\"]\n",
    "\n",
    "### Colums to scale, all except pdg\n",
    "col_scale = list (X_train.columns.drop(\"pdg_function\"))\n",
    "\n",
    "### Columns to categorize: pdg_function\n",
    "col_cat = [\"pdg_function\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate median column wise, for test_data only, return as a dict, leave out zeros\n",
    "def col_median(col):\n",
    "        ind = col > 0 ## Calculate Median from entries larger 0\n",
    "        col_med = np.median (col[ind]) # Calculate median\n",
    "        return col_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### scaling - standadization, applied in function. Differs if applied on training or test data set\n",
    "def scale_func (X_df, scaler = None, train = True):\n",
    "    \n",
    "    #X_scaled = X_df[col_scale]\n",
    "    if train == True: ### Scaling the training or test data?\n",
    "        scaler_1 = StandardScaler() # If scaling the training data, first the Scaler-Object is opened\n",
    "        X_scaled = scaler_1.fit_transform(X_df)\n",
    "\n",
    "        return scaler_1, X_scaled # Return ScalerObject and Scaled X\n",
    "    else:\n",
    "        X_scaled = scaler.transform(X_df)\n",
    "        return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### One hot encoding with enc = OneHotEncoder - similar structure as above , fit_transform for training data and transform for test\n",
    "### scaling - standadization, applied in function. Differs if applied on training or test data set\n",
    "def encode_func (X_df, col_cat, encoder = None, cat_dict = None, train = True):\n",
    "    \n",
    "    #X_encoded = X_df[col_cat]\n",
    "    if train == True: ### Encode training data and save category levels\n",
    "        # cast to categorical data and save the categories\n",
    "        cat_dict = {} # Save categories in dictionary\n",
    "\n",
    "        for col in col_cat:\n",
    "            X_df[col] = X_df[col].astype(\"category\")\n",
    "            cat_dict[col] = X_df[col].cat.categories\n",
    "\n",
    "        encoder_1 = OneHotEncoder(sparse = False) # If scaling the training data, first the Scaler-Object is opened\n",
    "        X_encoded = encoder_1.fit_transform(X_df)\n",
    "\n",
    "        return cat_dict, encoder_1, X_encoded # Return ScalerObject and Scaled X\n",
    "\n",
    "    else:\n",
    "        ### Transform to specified CategoricalDType()\n",
    "        for col in col_cat:\n",
    "            cat_type = CategoricalDtype(cat_dict[col], ordered = False)\n",
    "            X_df[col] = X_df[col].astype(cat_type)\n",
    "\n",
    "        #Â And then apply OneHotencoding\n",
    "        X_encoded = encoder.transform(X_df)\n",
    "\n",
    "        return X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing\n",
    "# in Function: 1. \n",
    "#               a) split off columns to replace zeros \n",
    "#               b) and categorical columns to dummy encode\n",
    "#              2. Replace zeros in a)\n",
    "#              3. Concat columns from 2. and remaining numeric columns\n",
    "#              4. apply scaling on 3.)\n",
    "#              5. apply dummy encoding on 1. b)\n",
    "#              6. concat 4. and 5.\n",
    "\n",
    "# Retain column names!\n",
    "\n",
    "def preprocess_diab(X_df, col_zero, col_scale, col_cat, medians_train = None, scaler = None, encoder = None, cat_dict = None, train = True):\n",
    "    # in Function: 1. \n",
    "    #               a) split off columns to replace zeros\n",
    "    X_zero = X_df[col_zero] # Works\n",
    "    # 1. b) and categorical columns to dummy encode\n",
    "    X_cat = X_df[col_cat]\n",
    "\n",
    "    # 2. Replace zeros in 1. a)\n",
    "    # Calculate Median Column wise if using the train set\n",
    "    if train == True:\n",
    "        medians_train = X_zero.apply(lambda x: col_median(x))\n",
    "    \n",
    "    # Replace with values from median train - Stores in X_zero\n",
    "    for col in col_zero:\n",
    "        repl_val = medians_train[col]\n",
    "        X_zero[col].replace(0, repl_val, inplace = True)\n",
    "        del repl_val\n",
    "    \n",
    "    # 3. Concat columns from 2. X_zero and remaining numeric columns\n",
    "    # Columns which do not have the zero colum and should be scaled\n",
    "    col_scale_no_zero = [col for col in col_scale if col not in col_zero]\n",
    "    # As their own df\n",
    "    X_no_zero = X_df[col_scale_no_zero] \n",
    "\n",
    "    X_scale = pd.concat([X_no_zero, X_zero], axis = 1)\n",
    "    ### Remember column names in the right order\n",
    "    x_scale_names = col_scale_no_zero + col_zero\n",
    "    \n",
    "    # 4. apply scaling on 3.)\n",
    "    if train == True:\n",
    "        scaler, X_scale = scale_func(X_scale, train = train)\n",
    "    \n",
    "    else:\n",
    "        X_scale = scale_func(X_scale, scaler, train = train)\n",
    "    \n",
    "    # 5. apply dummy encoding on 1. b)\n",
    "    if train == True:\n",
    "        cat_dict, encoder, X_encoded = encode_func(X_cat, col_cat, train = train)\n",
    "    \n",
    "    else:\n",
    "        X_encoded = encode_func(X_cat, col_cat, encoder, cat_dict, train = train)\n",
    "    \n",
    "    #  Get dummy names for each encoded column - > list of new column names for encoded data\n",
    "    x_encoded_names = []\n",
    "    for key, val in cat_dict.items():\n",
    "        for categ in val:\n",
    "            col_nam = key + \"_\" + str(categ)\n",
    "            x_encoded_names.append(col_nam)\n",
    "\n",
    "    ### Concat X_scaled and X_cat\n",
    "    X_preprocessed = np.concatenate([X_scale, X_encoded], axis = 1)\n",
    "    ### Reapply Names to feature data - seems to be not that easy...\n",
    "    preprocessed_names = x_scale_names + x_encoded_names\n",
    "\n",
    "    if train == True:\n",
    "        return X_preprocessed, preprocessed_names, cat_dict, encoder, scaler, medians_train\n",
    "    else:\n",
    "        return X_preprocessed\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed, preprocessed_names, cat_dict, encoder, scaler, medians_train = preprocess_diab(X_train, col_zero, col_scale, col_cat, train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_preprocessed = preprocess_diab(X_test, col_zero, col_scale, col_cat, medians_train, scaler, encoder, cat_dict, train = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use at least two different classification methods\n",
    "    - decision trees\n",
    "    - K-nearest neighbors\n",
    "\n",
    "- Choose and evaluation metric:\n",
    "    - Recall to minimize the percentage of false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HyperParameterTuning K-Nearest neighbors\n",
    "param_grid_knn = {\"n_neighbors\" : [2,5,7,10,15,20],\n",
    "                \"weights\" : [\"uniform\", \"distance\"],\n",
    "                \"p\" : [1,2,3,4,5]\n",
    "             }\n",
    "\n",
    "# Instantiate gridsearch and define the metric to optimize \n",
    "gs_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, scoring='recall',\n",
    "                  cv=5, verbose=5, n_jobs=-1)\n",
    "\n",
    "# Fit gridsearch object to data.. also lets see how long it takes\n",
    "start = timer()\n",
    "gs_knn.fit(X_train_preprocessed, np.ravel(y_train))\n",
    "end = timer()\n",
    "gs_time = end-start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best score\n",
    "print('Best score:', round(gs_knn.best_score_, 3))\n",
    "\n",
    "# Best parameters\n",
    "print('Best parameters:', gs_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best KNN model and predict\n",
    "gs_knn_best = gs_knn.best_estimator_\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred_test = gs_knn_best.predict(X_test_preprocessed)\n",
    "\n",
    "# Print accuracy score \n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test).round(2))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test).round(2))\n",
    "print(\"-----\"*10)\n",
    "\n",
    "# Print confusion matrix\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_test), annot=True, cmap='YlGn');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, penalty=l2;, score=0.725 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, penalty=l2;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, penalty=l2;, score=0.575 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, penalty=l1;, score=0.825 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, penalty=l2;, score=0.550 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, penalty=l1;, score=0.375 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, penalty=l1;, score=0.625 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, penalty=l1;, score=0.641 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, penalty=l1;, score=0.175 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, penalty=none;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, penalty=l2;, score=0.564 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, penalty=none;, score=0.475 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, penalty=none;, score=0.525 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, penalty=none;, score=0.641 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, penalty=l2;, score=0.575 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, penalty=l2;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, penalty=none;, score=0.425 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, penalty=l2;, score=0.650 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, penalty=l1;, score=0.825 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, penalty=l1;, score=0.590 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, penalty=l2;, score=0.725 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, penalty=l1;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, penalty=none;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, penalty=l2;, score=0.615 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, penalty=l1;, score=0.825 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, penalty=none;, score=0.725 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, penalty=none;, score=0.575 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, penalty=l1;, score=0.625 total time=   0.0s[CV 5/5] END alpha=0.0001, loss=log, penalty=none;, score=0.615 total time=   0.0s\n",
      "\n",
      "[CV 3/5] END alpha=0.0001, loss=log, penalty=none;, score=0.625 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_hinge, penalty=l2;, score=0.675 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_hinge, penalty=l2;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_hinge, penalty=l2;, score=0.513 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_hinge, penalty=l2;, score=0.200 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_hinge, penalty=l1;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_hinge, penalty=l1;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_hinge, penalty=l1;, score=0.675 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_hinge, penalty=none;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_hinge, penalty=l2;, score=0.700 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_hinge, penalty=l1;, score=0.769 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_hinge, penalty=l1;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_hinge, penalty=none;, score=0.800 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_hinge, penalty=none;, score=0.462 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_hinge, penalty=none;, score=0.475 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_hinge, penalty=none;, score=0.375 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.550 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=modified_huber, penalty=l2;, score=0.487 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=modified_huber, penalty=none;, score=0.575 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.575 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.300 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=modified_huber, penalty=none;, score=0.575 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, loss=hinge, penalty=l2;, score=0.550 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=modified_huber, penalty=none;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=modified_huber, penalty=l1;, score=0.769 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, loss=hinge, penalty=l2;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=modified_huber, penalty=none;, score=0.590 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, loss=hinge, penalty=l1;, score=0.550 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, loss=hinge, penalty=l2;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=modified_huber, penalty=none;, score=0.925 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, loss=hinge, penalty=l2;, score=0.575 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, loss=hinge, penalty=l1;, score=0.615 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, loss=hinge, penalty=none;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, loss=hinge, penalty=l2;, score=0.590 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, loss=hinge, penalty=none;, score=0.350 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, loss=hinge, penalty=none;, score=0.675 total time=   0.0s\n",
      "[CV 2/5] END .alpha=0.001, loss=log, penalty=l2;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, loss=hinge, penalty=none;, score=0.641 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, loss=hinge, penalty=l1;, score=0.625 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, loss=hinge, penalty=none;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END .alpha=0.001, loss=log, penalty=l2;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, loss=hinge, penalty=l1;, score=0.600 total time=   0.0s\n",
      "[CV 3/5] END .alpha=0.001, loss=log, penalty=l2;, score=0.700 total time=   0.0s\n",
      "[CV 1/5] END .alpha=0.001, loss=log, penalty=l1;, score=0.725 total time=   0.0s\n",
      "[CV 4/5] END .alpha=0.001, loss=log, penalty=l2;, score=0.550 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, loss=hinge, penalty=l1;, score=0.725 total time=   0.0s\n",
      "[CV 5/5] END .alpha=0.001, loss=log, penalty=l2;, score=0.538 total time=   0.0s\n",
      "[CV 2/5] END .alpha=0.001, loss=log, penalty=l1;, score=0.525 total time=   0.0s\n",
      "[CV 5/5] END .alpha=0.001, loss=log, penalty=l1;, score=0.513 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, loss=log, penalty=none;, score=0.575 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, loss=log, penalty=none;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, loss=squared_hinge, penalty=l2;, score=0.725 total time=   0.0s\n",
      "[CV 3/5] END .alpha=0.001, loss=log, penalty=l1;, score=0.700 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, loss=log, penalty=none;, score=0.564 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, loss=squared_hinge, penalty=l2;, score=0.525 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, loss=log, penalty=none;, score=0.550 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, loss=squared_hinge, penalty=l2;, score=0.550 total time=   0.0s\n",
      "[CV 4/5] END .alpha=0.001, loss=log, penalty=l1;, score=0.525 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, loss=squared_hinge, penalty=l2;, score=0.282 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, loss=squared_hinge, penalty=l2;, score=0.725 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, loss=log, penalty=none;, score=0.675 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, loss=squared_hinge, penalty=none;, score=0.487 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, loss=squared_hinge, penalty=l1;, score=0.625 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, loss=squared_hinge, penalty=l1;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.550 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, loss=hinge, penalty=l2;, score=0.550 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, loss=squared_hinge, penalty=none;, score=0.475 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.575 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, loss=hinge, penalty=l2;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.450 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.650 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, loss=modified_huber, penalty=l1;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, loss=modified_huber, penalty=l1;, score=0.775 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, loss=squared_hinge, penalty=none;, score=0.725 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, loss=hinge, penalty=l2;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, loss=modified_huber, penalty=l2;, score=0.641 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, loss=modified_huber, penalty=l1;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, loss=modified_huber, penalty=none;, score=0.575 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, loss=hinge, penalty=l2;, score=0.475 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001, loss=modified_huber, penalty=l1;, score=0.825 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, loss=hinge, penalty=l2;, score=0.564 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, loss=modified_huber, penalty=none;, score=0.575 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, loss=squared_hinge, penalty=l1;, score=0.625 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, loss=hinge, penalty=l1;, score=0.475 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, loss=modified_huber, penalty=l1;, score=0.825 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, loss=hinge, penalty=l1;, score=0.525 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, loss=modified_huber, penalty=none;, score=0.625 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, loss=hinge, penalty=l1;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, loss=hinge, penalty=l1;, score=0.538 total time=   0.0s\n",
      "[CV 2/5] END ..alpha=0.01, loss=log, penalty=l2;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, loss=hinge, penalty=l1;, score=0.700 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, loss=hinge, penalty=none;, score=0.575 total time=   0.0s\n",
      "[CV 3/5] END ..alpha=0.01, loss=log, penalty=l2;, score=0.625 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, loss=modified_huber, penalty=none;, score=0.450 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, loss=hinge, penalty=none;, score=0.550 total time=   0.0s\n",
      "[CV 4/5] END ..alpha=0.01, loss=log, penalty=l2;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, loss=hinge, penalty=none;, score=0.575 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, loss=modified_huber, penalty=none;, score=0.641 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, loss=hinge, penalty=none;, score=0.525 total time=   0.0s\n",
      "[CV 5/5] END ..alpha=0.01, loss=log, penalty=l2;, score=0.538 total time=   0.0s\n",
      "[CV 1/5] END ..alpha=0.01, loss=log, penalty=l1;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END ..alpha=0.01, loss=log, penalty=l1;, score=0.564 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, loss=hinge, penalty=none;, score=0.513 total time=   0.0s\n",
      "[CV 2/5] END ..alpha=0.01, loss=log, penalty=l1;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ..alpha=0.01, loss=log, penalty=l1;, score=0.650 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, loss=squared_hinge, penalty=none;, score=0.625 total time=   0.0s\n",
      "[CV 4/5] END ..alpha=0.01, loss=log, penalty=l1;, score=0.500 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, loss=log, penalty=none;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, loss=log, penalty=none;, score=0.525 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, loss=modified_huber, penalty=l2;, score=0.525 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, loss=log, penalty=none;, score=0.650 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, loss=squared_hinge, penalty=l1;, score=0.425 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, loss=squared_hinge, penalty=none;, score=0.550 total time=   0.0s\n",
      "[CV 1/5] END ..alpha=0.01, loss=log, penalty=l2;, score=0.600 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, loss=log, penalty=none;, score=0.525 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, loss=modified_huber, penalty=none;, score=0.525 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, loss=log, penalty=none;, score=0.564 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, loss=squared_hinge, penalty=l2;, score=0.475 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, loss=modified_huber, penalty=l2;, score=0.513 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, loss=modified_huber, penalty=none;, score=0.675 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, loss=modified_huber, penalty=none;, score=0.525 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.725 total time=   0.0s\n",
      "[CV 5/5] END .alpha=0.1, loss=hinge, penalty=l2;, score=0.513 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, loss=modified_huber, penalty=none;, score=0.513 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.525 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, penalty=none;, score=0.625 total time=   0.0s\n",
      "[CV 1/5] END .alpha=0.1, loss=hinge, penalty=l1;, score=0.425 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.675 total time=   0.0s\n",
      "[CV 2/5] END .alpha=0.1, loss=hinge, penalty=l1;, score=0.475 total time=   0.0s\n",
      "[CV 1/5] END .alpha=0.1, loss=hinge, penalty=l2;, score=0.550 total time=   0.0s\n",
      "[CV 3/5] END .alpha=0.1, loss=hinge, penalty=l1;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.475 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, penalty=none;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END .alpha=0.1, loss=hinge, penalty=l1;, score=0.375 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, loss=modified_huber, penalty=l1;, score=0.513 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, loss=squared_hinge, penalty=l1;, score=0.436 total time=   0.0s\n",
      "[CV 5/5] END .alpha=0.1, loss=hinge, penalty=l1;, score=0.487 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, loss=squared_hinge, penalty=none;, score=0.775 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, penalty=none;, score=0.575 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, loss=modified_huber, penalty=none;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, penalty=none;, score=0.525 total time=   0.0s\n",
      "[CV 2/5] END .alpha=0.1, loss=hinge, penalty=l2;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, penalty=none;, score=0.538 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, loss=squared_hinge, penalty=l2;, score=0.550 total time=   0.0s\n",
      "[CV 1/5] END ...alpha=0.1, loss=log, penalty=l1;, score=0.350 total time=   0.0s\n",
      "[CV 1/5] END ...alpha=0.1, loss=log, penalty=l2;, score=0.575 total time=   0.0s\n",
      "[CV 2/5] END ...alpha=0.1, loss=log, penalty=l1;, score=0.425 total time=   0.0s\n",
      "[CV 2/5] END ...alpha=0.1, loss=log, penalty=l2;, score=0.475 total time=   0.0s\n",
      "[CV 3/5] END ...alpha=0.1, loss=log, penalty=l1;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END .alpha=0.1, loss=log, penalty=none;, score=0.525 total time=   0.0s\n",
      "[CV 3/5] END .alpha=0.1, loss=hinge, penalty=l2;, score=0.575 total time=   0.0s\n",
      "[CV 3/5] END ...alpha=0.1, loss=log, penalty=l2;, score=0.575 total time=   0.0s\n",
      "[CV 4/5] END ...alpha=0.1, loss=log, penalty=l1;, score=0.300 total time=   0.0s\n",
      "[CV 4/5] END ...alpha=0.1, loss=log, penalty=l2;, score=0.475 total time=   0.0s\n",
      "[CV 4/5] END .alpha=0.1, loss=hinge, penalty=l2;, score=0.475 total time=   0.0s\n",
      "[CV 5/5] END ...alpha=0.1, loss=log, penalty=l1;, score=0.359 total time=   0.0s\n",
      "[CV 5/5] END ...alpha=0.1, loss=log, penalty=l2;, score=0.487 total time=   0.0s\n",
      "[CV 5/5] END .alpha=0.1, loss=log, penalty=none;, score=0.538 total time=   0.0s\n",
      "[CV 1/5] END .alpha=0.1, loss=log, penalty=none;, score=0.625 total time=   0.0s\n",
      "[CV 2/5] END .alpha=0.1, loss=log, penalty=none;, score=0.525 total time=   0.0s\n",
      "[CV 3/5] END .alpha=0.1, loss=log, penalty=none;, score=0.675 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, loss=squared_hinge, penalty=l2;, score=0.575 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=squared_hinge, penalty=l2;, score=0.600 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=modified_huber, penalty=l1;, score=0.575 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=modified_huber, penalty=l1;, score=0.475 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=squared_hinge, penalty=none;, score=0.615 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=modified_huber, penalty=l2;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=modified_huber, penalty=l1;, score=0.538 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, loss=squared_hinge, penalty=l2;, score=0.410 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=modified_huber, penalty=none;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=modified_huber, penalty=l2;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=modified_huber, penalty=none;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=modified_huber, penalty=none;, score=0.625 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=modified_huber, penalty=none;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=squared_hinge, penalty=l1;, score=0.550 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=squared_hinge, penalty=l2;, score=0.325 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=modified_huber, penalty=none;, score=0.564 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=modified_huber, penalty=l2;, score=0.650 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, loss=squared_hinge, penalty=none;, score=0.575 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=modified_huber, penalty=l2;, score=0.500 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=modified_huber, penalty=l2;, score=0.538 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, loss=squared_hinge, penalty=l2;, score=0.400 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=modified_huber, penalty=l1;, score=0.600 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, loss=squared_hinge, penalty=l1;, score=0.775 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=squared_hinge, penalty=l2;, score=0.275 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=modified_huber, penalty=l1;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, loss=squared_hinge, penalty=none;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=squared_hinge, penalty=l1;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=squared_hinge, penalty=l2;, score=0.375 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, loss=squared_hinge, penalty=none;, score=0.675 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, loss=squared_hinge, penalty=l1;, score=0.575 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=squared_hinge, penalty=l1;, score=0.675 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=squared_hinge, penalty=l2;, score=0.385 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, loss=squared_hinge, penalty=none;, score=0.513 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.01, loss=modified_huber, penalty=l2;, score=0.600 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.01, loss=modified_huber, penalty=l2;, score=0.525 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, loss=modified_huber, penalty=l2;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.01, loss=squared_hinge, penalty=l1;, score=0.700 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=squared_hinge, penalty=l1;, score=0.641 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=squared_hinge, penalty=l1;, score=0.350 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.01, loss=squared_hinge, penalty=l1;, score=0.675 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=squared_hinge, penalty=none;, score=0.350 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=squared_hinge, penalty=none;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.01, loss=squared_hinge, penalty=l1;, score=0.513 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=squared_hinge, penalty=none;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=squared_hinge, penalty=none;, score=0.675 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/gunnaroehmichen/neuefische/ds-diabetes-challenge/.venv/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### For logistic Regression - SGD Classifier\n",
    "# Defining parameter grid (as dictionary)\n",
    "param_grid_log = {\"loss\" : [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"], #this actually defines the model you use\n",
    "              \"alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "              \"penalty\" : [\"l2\", \"l1\", \"none\"]\n",
    "             }\n",
    "\n",
    "# Instantiate gridsearch and define the metric to optimize \n",
    "gs_log = GridSearchCV(SGDClassifier(random_state=RSEED), param_grid_log, scoring='recall',\n",
    "                  cv=5, verbose=5, n_jobs=-1)\n",
    "\n",
    "# Fit gridsearch object to data.. also lets see how long it takes\n",
    "start = timer()\n",
    "gs_log.fit(X_train_preprocessed, y_train)\n",
    "end = timer()\n",
    "gs_time = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.793\n",
      "Best parameters: {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "# Best score\n",
    "print('Best score:', round(gs_log.best_score_, 3))\n",
    "\n",
    "# Best parameters\n",
    "print('Best parameters:', gs_log.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will do this at least twice.. according to DRY we should write a function\n",
    "def print_pretty_summary(name, model, y_test, y_pred_test):\n",
    "    print(name)\n",
    "    print('=======================')\n",
    "    print('loss: {}'.format(model.loss))\n",
    "    print('alpha: {}'.format(model.alpha))\n",
    "    print('penalty: {}'.format(model.penalty))\n",
    "    accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    print('Test accuracy: {:2f}'.format(accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier model\n",
      "=======================\n",
      "loss: modified_huber\n",
      "alpha: 0.001\n",
      "penalty: l1\n",
      "Test accuracy: 0.708333\n"
     ]
    }
   ],
   "source": [
    "# Assigning the fitted SGDClassifier model with best parameter combination to a new variable sgd_best\n",
    "sgd_best = gs_log.best_estimator_\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred_test = sgd_best.predict(X_test_preprocessed)\n",
    "# Let us print out the performance of our model on the test set.\n",
    "sgd_accuracy = print_pretty_summary('SGDClassifier model', sgd_best, y_test, y_pred_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Diabetes-Challenge.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "fa0cc12332ff966f7de3ba169e4d017036cabaf84ddbe2009ca15c5bc06f98c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
